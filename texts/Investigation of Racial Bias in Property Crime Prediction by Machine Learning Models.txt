Property crime is one of the most common types of crime committed and reported in the United States. The scientific study of criminology is used to understand natural crime factors and identify its most common characteristics. Research on ways to reduce crime is crucial due to its potential solutions to prevent the harmful effects of crime on individuals and society. Predictive policing methods assist in intervention by focusing on the multiple causes of crime. Reduction of property crime can produce substantial economic benefits for individuals, communities, and taxpayers. Predictive policing uses algorithms to analyze data to predict and help prevent future crimes. Predictive policing methods based on machine learning algorithms have been used by police forces in the past. Programs such as PredPol and LASER have been used by the Los Angeles Police Department. However, marginalized racial demographics, primarily Black and Hispanic, were targeted by these predictive policing models, an unethical approach to crime reduction. Racial bias in predictive policing is especially destructive as it perpetuates systemic racism and unfairly targets racial minorities. Investigations into these predictive policing programs showed that the algorithms were person-based, meaning that models were trained on profiles of specific people. This made the models prone to racial bias in factors such as recidivism or victimization patterns already prevalent in policing. As a result, these models perpetuated cycles of bias present in the current U.S. criminal justice system, which unfairly targeted underprivileged racial minorities. However, with the use of pure crime report data and less problematic features in the preprocessing stage, we discover a more ethical alternative to pre-existing crime prediction models. Existing literature on crime prediction utilizes black-box machine learning models. Our models provide both accurate crime predictions and interpretation of risk factors. Compared to more popular techniques such as Risk Terrain Modeling and Kernel Density Estimation, decision tree models greatly outperform. Tree-based models partition data into small groups by recursion. The data splits are described by if-then statements, visualized by a tree. Popular decision tree models like Random Forest and XG-Boost can achieve low bias and low variance because of these characteristics. Random Forest and XG-Boost were chosen for our model because they result in wider diversity and are more attractive models for crime forecasting. Specifically, they calculate the average of each individual tree and search for the best feature among a random subset of features. Their performances are tested against another supervised machine learning model: K-Nearest Neighbor. K-Nearest Neighbor has similar advantages to Random Forests by selecting a specified number of examples closest to the query and averaging the labels. However, one disadvantage of decision tree models is their poor interpretability in determining the exact reason why a specific geographic area is a hotspot for crime. In our study, we attempt to combat this disadvantage by running feature importance to determine the largest risk factors. At the same time, feature importance assists in the objective to produce models with greater racial impartiality when predicting crime. Geographic Information Systems (GIS) create, manage, analyze, and map all types of data. They assist in increasing the interpretability of our model. GIS plays an important role in crime research through geospatial analysis capabilities. Relationships between crime and risk factors are easily discovered through GIS, and hotspot maps are easily produced to compile model output. In our model, a popular GIS software, ArcGIS, is used to help partition crime data into census tracts, where population and demographic data are extracted. ArcGIS was chosen because of its convenient capabilities as well as its capacity to assist in our preprocessing and racial bias analysis. We can run analyses on comparisons between predictions and actual results of a test dataset. ArcGIS will be able to determine if crime is being underpredicted or overpredicted in areas with greater racial features. Results are visualized through a plot generated by the GIS software. The final model is kept constant for further analyses. The crime rate derived from the model’s performance on the testing dataset is mapped against the actual crime rate in their respective census tracts. Using ArcGIS, the accuracy of our model is visualized on two choropleths. Similarities between these choropleths support the relative accuracy of our model in predicting the target variable. We introduce feature importance analysis on the model. From our final training dataset, ten population by race features are weighed against other geographic and demographic variables. Features that align with the trends of the target variable are labeled with higher feature importance. The results of the analysis are graphed as a correlation heatmap. Population features of commonly marginalized demographics have low relative importance. “% Black” and “% Hispanic or Latino” population features have negative correlation with the target variable with values of -0.03 and -0.14 respectively. Variables with higher relative importance such as “Vacant Units” are reflective of current studies on the popular contributing factors to crime. Research has shown that concentrations of vacant and deteriorated buildings tend to be hotspots for crime. One study conducted by Case Western Reserve University focused on the city of Cleveland. Researchers found that higher rates of crime correlated with vacant homes and lots. The model's impartiality was analyzed by comparing predicted and actual target variables. The scatterplot was created by ranking Black and Hispanic population features from lowest to highest percent of the total population and calculating the average value of both features. If the model overpredicts in areas with high proportion of minorities or underpredicts in areas with low proportion of minorities, we hypothesize that the model has high racial bias. However, the scatterplot shows that the model does the opposite. It overpredicts in areas with low minority population and underpredicts in areas with high minority population. Thus, we conclude that our model is not influenced by minority population features in its property crime predictions. Our methodology for predicting crime using a model trained on pure crime reports and demographic data has the potential to create less racially biased predictive policing models. This is because the training data is inherently impartial. Reported crimes (or calls for service) can be a biased measure depending on the preconceived notions of individuals in a population. Ground truth data may reflect racially disproportionate propensities to engage with the police. Based on our results, our model suggests that Boston produces crime report data that is less racially biased. The usage of this pure crime report data instead of past incrimination data like recidivism rates may also be a factor in this conclusion. The model can combine less biased data and less biased features to create accurate and more impartial predictions. With impartial models, we can provide more fair and ethical measures for predictive policing. The findings of our research emphasize the importance of analyzing bias in unprocessed data and during the preprocessing of specific data columns. Ultimately, an unbiased model can ethically assist police departments by policing more in predicted crime hotspots as a form of deterrence. There are several potential areas for future research beyond this study. With greater availability of data, we seek to evaluate racial features that may disproportionally contribute to property crime in other publicly available datasets. For future research, other algorithms for prediction may be explored to limit overfitting of the model. Older crime report data can also be experimented with to improve the accuracy of the model and obtain greater insight on any inherent bias in the model. A wider range of sources of report data can be extracted from other cities. Data of other types of crime aside from property crime may also be used to analyze bias. Future analyses may also be done on the model to specifically ensure its impartiality or sensitivity towards certain variables that pertain to race. One approach to addressing bias in machine learning models is to use techniques such as data augmentation and weighting to balance the representation of different groups in the training data. Developing methods for preprocessing or imputing raw biased data may also be a worthwhile pursuit. As racial bias is still a common social issue in policing, future work should continue to discover methodologies to train or isolate impartial models that do not perpetuate existing biases.
