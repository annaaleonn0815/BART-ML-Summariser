
Much has been written about the specifications and effects of machine learning (ML) systems, variously assessing, critiquing, and/or hyping their technical and social significance. Less attention, however, has been dedicated to ML technologies as objects of design—implements with technical features that could be otherwise, fabricated through subjective and creative choices. This omission is notable, as ML technologies are integral across major institutions, implicated in consequential decisions, and interwoven with the paces and practices of everyday life. How these systems are designed matters. Considered attention from the design studies tradition is thus a generative intervention in the production and understanding of ML systems, and the task to which this paper is set. In particular, I apply a central construct from design studies—affordances—to the ML domain, mobilizing an operational framework from which to evaluate, build, and reimagine ML applications. This move scaffolds a bridge between ideals and execution, alleviating the perennial principles-to-practice gap that has long plagued AI and ML fields. The design of technological systems is the design of social systems, deriving from and shaping both culture and practice. As a discipline, design studies is premised on the notion that human behaviors and experiences are affected by the contours and levers of designed objects. This base postulate has long circulated through myriad professional sectors such as user experience (UX) research, law, hardware and software development, human-computer interaction (HCI), robotics, engineering, architecture, and education via a common conceptual tool: technological affordances. In its simplest sense, affordances are the ways technical features enable and constrain for socially situated subjects. Assessing and in-building particular affordances through combined feature sets has been a central practice across spheres of technological design. Here, I extend affordances to ML through the mechanisms and conditions framework, an operationalization attending to dynamism in both subjects and structure. I begin by motivating the argument with two fundamental assumptions, before delving into a concise overview of affordances in technological design, including a summative description of the mechanisms and conditions framework. I then explicate how the framework applies to the domain of ML and highlight the relevance of an ML-affordance pairing. With this foundation set, three case examples exhibit the utility of affordances for ML and demonstrate how practitioners can apply the mechanisms and conditions framework for targeted ends of analysis and (re)design. Based in design studies, theories of affordance have long been central to understanding and intervening in the development and analysis of technological systems, yet ML has remained outside of the design studies purview. This is perhaps a function of ML as data driven, and thus less obviously conceived as an object of design. As I have demonstrated, however, ML systems and the models on which they run are subject to myriad design decisions which both reflect and shape the social worlds in which these systems operate. The present work thus extends affordances to ML, anchored by the M&C framework. Through three case examples across work, policing, and housing justice, I show how the M&C framework can illuminate the ways both technological and social systems afford across subjects and circumstances. Not only does this bring affordances (and design studies more broadly) to the field of ML, but also shows by example how to mobilize the M&C framework as a critical tool of both revelation and (re)making, scaffolding a path between principles and practice. Beyond this core contribution, I conclude with four key takeaways to guide affordance studies of ML systems going forward. The first point is that analysis and design are intertwined. Though presented distinctly across the case examples herein, analysis and design are inextricable and reciprocally connected. Analyses should be done with an aim towards remaking, while objects remain always in process and under analytic scrutiny, subject to adaptation and dismantle. This reciprocal relation is especially relevant to objects that develop through machine learning as they are never complete and always responsive to the data of a dynamic social world that has, and continues to, reflect, perpetuate, and intensify patterns of social order. Point two builds on yet also complicates the first: though analysis and design are intertwined and ongoing, front-end planning should take precedence. Once a system is built, it runs on its own inertia. Adjustments and retrofits overlaid upon a faulty core may alleviate some harms, but remain tied to a basic set of parameters from which deviations are necessarily limited and alternative pathways preemptively foreclosed. Moreover, as Ehsan and colleagues point out, ML applications can leave imprints upon the people and institutions through which these systems are implemented, such that effects endure even after an ML system discontinues. Point three goes back to the socio-structural character of technological systems, and the ways these systems are always and inevitably embedded within political economies of interests and power. Those working at the intersection of affordances, technology, and the law are especially instructive here, reckoning with the ways policies and regulation materialize with and through hardware, software, and code. This is a vital point when considering the case examples presented above—each of which contend with institutional actors backed by corporate and/or state authority. Put plainly, one cannot expect such institutions to redesign if they do not perceive it in their interests to do so. However, ML standards can be compelled through interrelated efforts of collective action, organizational policies, and legislative interventions which together, focus social, regulatory, and legal attention upon sociotechnical configurations. Such efforts can be aided by, developed through, and implemented with the M&C framework. Finally, identifying affordances—as they are in analysis and how they ought to be, in design—is contingent on the people in the proverbial room. Everyone has a standpoint that renders some things more observable and others, less. But, if we take seriously the canonical feminist point that those on the margins offer a uniquely valuable perspective for their recognition of realities otherwise clouded by privilege, then the White masculinity of computational professions becomes acutely salient. As D’Ignazio and Klein point out, data and computational sciences (broadly conceived) suffer from a ‘privilege hazard’, by which those who make and evaluate technological systems cannot access, predict, or understand the harms that will ensue for people unlike themselves. An affordance approach and its manifestation through the M&C framework requires sharp social attunement, best deployed through many and diverse hands. This means efforts at design and audit that give access to the outside, that place affected communities at the center, and that approach with humility, honesty, and a readiness to respond when the machines that decide, assist, govern, and predict inevitably learn to reproduce (and regress) the social systems of which they are a part. The logics and tools of design studies, including affordances, do not solve the troubles wrought by AI, automation, machine learning, or any other technological system, nor do they promise the realization of social good. These logics and tools do, however, draw explicit links between technical choices and their social effects, making these connections observable and thus actionable. Such a linkage is necessary, if not sufficient, for deliberate and considered approaches that hold technological systems and those who make and deploy them to account, and for building technologies that reflect and contribute to renditions of society that we hope to achieve. The M&C framework, in particular, attends to how, for whom, and under what circumstances technologies operate, by which a simple vocabulary exposes sociotechnical complexities underneath. As applied to the ML domain, the framework has been shown here as an instrument of analysis, (re)design, dismantle, and critical reflection. It also joins together design studies and machine learning, laying a foundation for this generative pairing
