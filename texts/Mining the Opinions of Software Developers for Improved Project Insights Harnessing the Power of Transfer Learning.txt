Sentiment analysis is a process of extracting the emotion of users from textual data. Sentiment Analysis techniques can be categorized into lexicon-based, machine-learning-based, and hybrid techniques. Applications of sentiment analysis also vary from monitoring the reputation of a product to tracking voters’ feelings and in financial markets. Similarly, some applications of sentiment analysis in software engineering is evaluation of product features, requirements prioritization, and product rating. Existing research shows that the accuracy and precision of domain-specific sentiment analysis are better than general-purpose tools as these tools’ accuracy depends on the lexicon/dictionary. Furthermore, various machine learning techniques being the popular techniques for developing sentiment classifiers for sentiment analysis were also studied, but the results of these techniques are quite diverse. Sentiment analysis is valuable in software engineering because one can capture users’ opinions about a particular application or feature. The main sources of opinion data in software engineering are app reviews, bug reports, and community question-answering sites. Existing sentiment analysis tools give negative results when applied to the software domain. Therefore, research is underway to develop domain-specific sentiment analysis tools for software engineering. However, existing sentiment analysis tools developed for the software domain also have various limitations. Firstly, these tools typically demonstrate efficacy only within the confines of a particular dataset, limiting their generalizability and applicability across diverse contexts. Moreover, their performance may be influenced by inherent biases present within the data, potentially skewing the analysis results. Additionally, a notable challenge faced by existing tools is their difficulty in accurately computing negative and neutral sentiments, which can lead to imprecise or misleading analyses. There is a need to overcome the above-stated limitations and develop a reliable sentiment analysis tool that works well on all software engineering datasets. Therefore, in this research, a large-scale study is conducted in which various classifiers are developed and fine-tuned by using different feature sets. The purpose of this effort is to develop a reliable sentiment analysis tool and evaluate the performance of various algorithms for domain specific sentiment analysis. These classifiers are trained on publicly available SentiSE dataset. It is observed that the performance of the transfer learning models is better than the machine learning and deep learning models for sentiment analysis. Therefore, transfer learning models are declared as the best models in this research and are used in further experiments of this research. The fine-tuned transfer learning models are validated using different experiments that were conducted using eight machine learning, and four deep learning models. In addition to this, different publicly available software engineering datasets are also used for validation to show the strengths of fine-tuned models on new datasets. The performance of the best models is also compared with the existing state-of-the-art sentiment analysis tools developed for the software domain. The Bert-Large model gives the best results as compared to state-of-the-art tools on the Stack Overflow and Jira datasets. This research presents several significant contributions that aim to advance sentiment analysis within the software engineering domain: Unlike many existing studies that primarily focus on training sentiment analysis classifiers within specific domains, this research leverages transfer learning-based classifiers. This approach significantly enhances the accuracy and generalization of sentiment analysis models across various software engineering datasets. The F1-Score of Bert model is 0.89 that is higher than the various classifier based techniques. To the best of knowledge this is the first research that fine-tune GPT for domain specific sentiment analysis within software engineering. While previous works often report results on a single dataset on which it was trained, this study conducts a comprehensive benchmarking exercise. The proposed model is systematically evaluated on a wide range of machine learning and deep learning classifiers across multiple publicly available software engineering datasets. This approach cover the limitation of existing sentiment analysis tools. A newly developed, customized versions of GPT and BERT models specifically tailored for sentiment analysis in software engineering are introduced. Experiments demonstrate that these customized models outperform all state-of-the-art methods on the SE datasets, achieving higher accuracy and performance levels, thereby setting a new standard for sentiment analysis within the domain. By establishing a benchmark for sentiment analysis classifiers in software engineering, this research serves as a foundational reference point for future investigations. The performance of transfer learning classifiers is compared against existing state-of-the-art sentiment analysis tools in the SE domain. This comparison highlights the superiority of the proposed approach, particularly demonstrated by the significant improvement in F1-score achieved by the Bert large model on the Stack Overflow dataset. The remaining paper is organized into the following sections. Section II covers the related work. Research methodology is given in Section III. A detail of experiments with different classifiers is given in Section IV. Best tools are validated with different datasets in V and comparing best classifiers with the existing state-of-the-art tools is made in Section VI. Finally, Section VII concludes this paper. In this research, a comprehensive large-scale study was undertaken, with the primary objective of improving sentiment analysis accuracy in the domain of software engineering by using transformers. The study involved training various sentiment analysis classifiers and evaluating their performance against existing sentiment analysis tools in the field. Notably, an extensive pre-processing stage was employed to enhance the accuracy of the classifiers. The selection of the SentiSE dataset, derived from diverse software engineering interactions, as the training data, reflects a commitment to capturing the nuances of sentiment within the domain. Among the various models explored, including XGBoost, Bert-Base fine-tuned model, Bert-Large, and GPT fine-tuned model, the results underscored the exceptional performance of Bert-Large across multiple datasets. For instance, the Bert-Large model achieved an accuracy of 0.806 on the JavaLib dataset, 0.766 on the Jira dataset, and 0.888 on the Stack Overflow dataset. It is worth noting that these results exhibit a remarkable level of accuracy, particularly in challenging domains such as software engineering. An insightful aspect of the evaluation is that the Bert-Large model surpasses all other existing state-of-the-art sentiment analysis tools on both the Jira and Stack Overflow datasets. This not only signifies the effectiveness of the Bert-Large model but also underscores its potential as the go-to tool for sentiment analysis in these specific domains. Furthermore, the Bert-Large model exhibits comparable performance to SentiCR on the Jira dataset, while surpassing Senti4SD, a model trained specifically on the Stack Overflow dataset. These results emphasize the versatility and superiority of the Bert-Large model across a spectrum of software engineering datasets. In summary, the findings of this research not only provide evidence of significant improvements in sentiment analysis accuracy within the software engineering domain but also establish the Bert-Large model as a robust and superior choice when compared to existing state-of-the-art sentiment analysis tools, particularly on Jira and Stack Overflow datasets. Efforts are underway to improve the accuracy of fine-tuned Bert-based classifiers for sentiment analysis of software domains. For this purpose class balancing and data smoothing techniques will be used.
