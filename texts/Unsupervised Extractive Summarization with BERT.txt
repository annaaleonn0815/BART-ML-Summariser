Nowadays, there is a large amount of written text on every topic as the worldâ€™s knowledge is easily available, from extensive news articles to Wikipedia pages. Since much of the information is structured in large documents and articles, there is an increasing need to summarize and process written text. This work introduces new methods for automatic summarization and compares several alternative models for this task. The focus is on preserving contextual meaning and reproducing the manner in which a person might approach this task. Summarization is particularly challenging in low-coverage languages since little research is available, and large annotated corpora for training complex models are not available. The objective is to overcome this drawback by proposing several models that compute relevant summaries and build an annotated dataset for further reference. Automatic summarization involves shortening a document or a collection of documents while preserving its meaning and context. Various compression percentages are used depending on the desired size of the summary, the complexity of the document, and the type of summarization. Automatic summarization can be classified into two types given its output, with a third hybrid type being added as an alternative. Extractive summarization involves selecting a subset of sentences from the original document and assembling them to form a summary. The main advantage of this technique is the correctness of the resulting text and the well-preserved semantic meaning. However, a drawback is its inability to preserve a smooth speech flow, as some extracted sentences may not have a logical semantic connection with adjacent fragments. Abstractive summarization produces a rephrased summary that closely resembles a human-built summary in terms of discourse coherence, but a major drawback is that grammatical and semantic correctness may not be preserved, which can result in altered concepts and vague meanings. Abstractive models also require large training datasets for language comprehension and generation. For this reason, this work focuses on extractive summarization, emphasizing the need to build a suitable corpus and value informative summaries over speech coherence. Ongoing research in text summarization and Natural Language Processing has mainly been conducted in English and other world languages, with a significant lack of summarization corpora for other languages like Romanian. The annotations require a lot of human effort and are time-consuming, as existing Romanian websites do not provide extractive excerpts for their documents. Low interest and limited research capabilities in studying other languages have contributed to almost non-existent research on this topic. However, progress has been made with pre-trained encoders and NLP tools, establishing a foundation for text summarization. This paper introduces a novel unsupervised method for text summarization based on pre-trained Transformer models, namely MLM for sentence importance, and compares it with some of the most popular unsupervised methods for this task. A small dataset with 100 Romanian texts and their corresponding summaries was built to assess the performance of different approaches. The corpus also serves as a test dataset for further exploration and research on this topic. The next section presents state-of-the-art models and techniques proposed for language models, summarization, and metrics. The third section covers the employed methods for extractive summarization in the Romanian language and offers insights into how the evaluation dataset was constructed. The next section presents the results obtained by our models, and the final section concludes the findings and lays out the foundations for future work. Both datasets are built for extractive summarization; therefore, accuracy is used to evaluate the performance of the models. Besides accuracy, metrics typically used for abstractive summarization, such as ROUGE and METEOR, are considered to capture similar sentences not selected by human annotators but still relevant as summaries. As seen in Table II, PacSum performs best on the ROUGE evaluation metric, followed closely by our model, MLM for sentence importance. The distinction between them is that our model is a randomized algorithm, and its scores needed to be aggregated. PacSum performs best on news articles, prioritizing sentences that appear first, as many news articles are written so that the main topic is concentrated at the beginning. K-Means with BERT Embeddings is the third-best choice for our dataset, while the approach with MLP on Handcrafted Features performs the worst. METEOR, a metric initially used for translation and later adopted for text summarization due to its corresponding features and consideration of synonyms, often correlates better with the human way of thinking and can be more relevant than other metrics. Our model performs best for this metric. In terms of accuracy, Pacsum is the best model, followed closely by MLM for sentence importance. The MLP on handcrafted features outperforms K-Means with BERT Embeddings for this metric since it is trained to maximize accuracy, often at the expense of other metrics. However, Table III shows a different situation where the MLP on handcrafted features outperforms all other methods for the Romanian dataset. The large corpus used for training and testing the Neural Networks model plays a crucial role in this performance, suggesting that a supervised method is preferable if large datasets are available. The aim of this paper was to propose and compare several methods for extractive summarization in the Romanian language, using mostly unsupervised models and a supervised neural network. A test dataset of 100 extractive summaries was also proposed to evaluate the summaries generated by the employed models. Several baseline models were implemented, including K-Means with BERT embeddings, MLP on handcrafted features, and Pacsum, which establishes the relevance of a sentence differently, with PacSum proving to be the most suitable with the highest ROUGE score. The final method implemented considers our approach, MLM for sentence importance, which mimics how a person summarizes a document by removing one sentence at a time while predicting masked words based on the remaining context. The masked words are relevant nouns and verbs that establish the document's main topic. The quality of predictions is inversely proportional to the importance of the removed sentence for understanding the article. A sentence score is calculated based on the difference between the loss value for predicting masked words before and after removing the sentence. Our approach was highly effective, reaching ROUGE scores comparable to the state-of-the-art and outperforming PacSum in the METEOR metric. Our results suggest that PacSum and MLM for sentence importance are the most suitable models for extractive summarization in the Romanian language, achieving the highest scores for our corpus without requiring a training set. For the English corpus, the best method proved to be the MLP on handcrafted features trained on the BBC News dataset. All methods use pre-trained BERT and RoBERT representations, but these models are trained using unlabeled datasets, indicating that bidirectional transformers can be trained and fine-tuned for summarization in every low-coverage language. Future improvements could enhance the corpus through continuous crowdsourcing of annotators to add new summarized content and reduce bias through peer review of already annotated articles. A dataset with over 500 summaries could be a stepping stone for training supervised methods for Romanian. An improvement for MLM for sentence importance would be to determine which words should be masked, possibly including non-randomized choices, considering more parts of speech or words relevant to the document's main topic. Additionally, optimizations in speed must be performed to enable multiple computations of the score for one sentence and the aggregation of these results, as the algorithm is randomized and should not rely entirely on a single score.
