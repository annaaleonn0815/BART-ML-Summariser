The internet has become a hub of information and every single day, the articles on the internet are rising at a rapid pace, and so does the associated redundancy. It is necessary to read all these articles to get a complete insight into the topic, which is a time-consuming process. It is essential to find a solution to reduce the information into meaningful and manageable summaries. These summaries will be expected to focus on the salient details, while reducing the redundancy. It proposes to use neural networks and Natural Language Processing techniques to develop an efficient and accurate tool to summarize multiple documents pertaining to one topic, into a single concise piece of abstractive summary. Text Summarization is a way of converting a given large block of information into a smaller version preserving its content, overall semantics, meaning and purpose. Manual summarization of articles is a very difficult task. The two main ways of automatic summarization are: extraction and abstraction. Extractive methods of summarization try to identify the important parts of the text and only extract the whole sentences from the original documents. On the other hand, abstractive summarization methods create summaries in a more humanlike way. They use advanced natural language techniques and interpret the text, to generate a summary that uses a new set of sentences altogether. In this paper, we have covered abstractive summarization using an unsupervised graph-based approach to convert an entire document into a word-graph and then traverse it to figure out valuable patterns and form sentences using the most important parts of the document. Word graphs are generated for documents that are clustered based on their contexts and importance analysis. The findings and inferences achieved from our work in extractive summarization are briefly discussed and further used effectively in the actual innovation in the form of an abstractive multi-document summarizer. An actual abstractive summarizer would have a natural understanding of how a language works and can generate sentences like humans do. Finally, we evaluate our results using ROUGE1 metric which is Recall-Oriented Understudy for Gisting Evaluation and BLEU2 metric which is short for Bilingual Evaluation Understudy. These metrics quantitatively describe how accurately a system generated summary reflects the main contents of all documents
