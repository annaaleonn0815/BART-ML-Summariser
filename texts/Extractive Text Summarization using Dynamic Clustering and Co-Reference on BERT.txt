Text summarization, in the field of natural language processing, refers to the process of preserving only the most salient parts of the information which captures the most meaning from the entire block of text. The main aim is to create a subset of the information present in the text which can be substituted to understand the meaning of the whole of the data. Each day we create and consume data at extremely high rates than ever before which makes text summarization a fundamental requirement for many companies along the lines of business analytics, media monitoring, social media marketing, etc. With the level of technology, it is possible to summarize huge documents in just a few seconds by the process of automatic text summarization. Summarization helps us to consume the information we create but in a faster manner. It helps us to retrieve an accurate summary of the text which is not only short but also captures all the context of the data. Automatic summarization has a variety of applications based on diverse use cases and document types and these summarization systems can be classified into distinct categories. The two principal categories are â€“ abstractive and extractive. The summary phrased by humans in their wordings based on their understanding of the passage is called an abstractive summary. These summaries preserve the meaning of the passage but comprise sentences worded very differently from that of the original passage. Thus, these kinds of summaries are still a challenge for machines to produce as the vocabulary of the user needs to be taken into account each time it is used. Since these summaries are not yet up to par, companies are opting to move the extractive summarization as the solution. Extractive summaries are created by directly choosing sentences from the original text by assigning scores to sentences or by creating clusters to group similar sentences. These summaries do not contain any rephrased information, rather only the most important sentences from the text. Currently, numerous methods for extractive summarization exist, each solving a drawback of another. But none of them are perfect and this provides an opportunity to continue finding breakthroughs in this area of automation. One of the most noticeable factors in any machine produced summary is the length which is always a predetermined ratio by the programmer. Also, the quality of the summary produced is drastically affected when sentences are discarded for lack of context. The outcome of this project is an automated extractive summarizer, which is backed by BERT and is modified for providing context to sentences and dynamically determining the size of the machine produced summary using machine learning algorithms. This study is an improvement over the work done by Derek Miller (2019) which summarizes lectures. The result of the study is a restful API service and tool operable from the command line to summarize any given lecture. There are two main components in this lecture. Firstly, users can manage the creation and storage of lectures and its corresponding summaries. Secondly, the BERT model produces sentence embeddings from the K-means clustering which are then used in the inference. The input paragraph is firstly tokenized into sentences which are passed to the BERT model to produce the embeddings which are then clustered using K-means clustering. Finally, sentences which are closest to the centroid of each cluster are chosen to be a part of the final summary. The main disadvantage of the existing model was that the entire context of the document to be summarized could not be represented in a smaller number of sentences. This could work in the case of abstractive summarization as the context of multiple sentences could be combined. However, in the case of extractive summarization, a greater number of sentences are required to represent a large document. We aimed to create summaries for large documents, and we have overcome the disadvantages of a short summary by improving the size of the summary depending on the size of the story. The CNN/DailyMail dataset had gold standard summaries of constant length irrespective of the size of the document to be summarized. Hence the linear regression model that was trained between summary length and WCSS/BCSS was not accurate. A dataset with summaries that were more representative of the document size would have fared better. In the proposed model, the base version of the pre-trained BERT model has been used. In future models, variations of BERT should be compared and tested; the BERT model can be finetuned and trained from scratch for obtaining results with more precision, which would again require larger datasets and time for training. Our work mainly revolved around CNN/Dailymail dataset and results were local to this dataset. In the future, the proposed model can be made to run on other standard datasets like document understanding conferences (DUC) and The New York times (NYT) news. One of the issues that we faced with CNN-Dailymail Dataset was that most of the reference/gold summary contained only 3-4 sentences which cannot be taken as a standard for predicting the number of sentences in the generated summary dynamically. To solve this, the proposed model must be run on various datasets available having a reference summary of varying lengths. Our main goal was to help students who have to go through pages of lectures by providing them with a reliable summary that captures the whole context and at the same time reducing the size of the document to the optimal length. Thus, the future work is to deploy the model on lectures from various massive open online courses (MOOC) platforms like Coursera and Udemy. To make this user friendly, a website can be developed to take the document as input from the user which then provides the user with the required summary. Also, the user may be prompted to give feedback on the generated summary which can be used in further improving the model.
