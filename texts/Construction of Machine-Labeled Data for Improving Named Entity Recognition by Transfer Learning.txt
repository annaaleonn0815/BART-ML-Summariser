Named entity recognition (NER) is one of the natural language processing (NLP) tasks that detects named entities in a given text and classifies them into predefined categories such as person, location, organization, date, and time. NER results provide abundant information to downstream NLP tasks. For example, in a question answering (QA) system, a named entity classified as a person is considered a strong candidate to answer the question, "Who?" Thus, NER is a fundamental and significant task for NLP applications such as QA, machine translation, and dialogue systems. In recent years, deep neural networks (DNNs) have achieved higher scores than previous approaches on almost every NLP task, including NER. However, DNNs require a large amount of training data to perform well. As DNNs contain many weights, the weights have to be tuned with training data. However, the amount of labeled data available is significantly less than unlabeled data in the real world. Despite unlabeled data being plentiful, using it is difficult because manual labeling is time-consuming and expensive. In particular, NER is a task that frequently requires a new labeled dataset depending on named entity tags, making it especially laborious. In other words, if the type of named entities to be predicted is different, a new NER dataset must be labeled with newly named entity tags. Therefore, we propose a method for improving NER systems that suffer from insufficient training data problems by using a large amount of unlabeled data and a small amount of labeled data. Bootstrapping is a traditional approach used in various research fields to overcome the problem of insufficient training data. The bootstrapping approach creates a more accurate classifier that automatically labels data. The process of bootstrapping is as follows: a classifier is trained with a small set of data, and then the trained classifier predicts labels for the unlabeled data. The trained classifier is then retrained with the generated data, which provides more patterns to the classifier, thus increasing its performance. As the process repeats, the classifier is improved and the amount of automatically labeled data increases. Consequently, a considerable quantity of labeled data is acquired without additional human labeling. With the advancement of DNN-based NLP models, there has been increasing interest in using transfer learning to alleviate the limited performance owing to insufficient data, even in areas such as image classification and speech recognition. Transfer learning is a method that utilizes information trained from other related tasks (sub-tasks) to solve the target task. It is well-known that deep learning models first trained on a subtask typically perform better than those that use randomly initialized models to train the target task. The training process for the subtask is called "pre-training," and the training for the target task is called "fine-tuning." Our proposed method to resolve the insufficient training data problem in NER is based on the bootstrapping and transfer learning approaches. The advantage of the bootstrapping approach is that it automatically generates labels for unlabeled data at a low cost. For this reason, we generated labeled data with the bootstrapping approach. We called the data created in this way "machine-labeled data." Furthermore, to utilize the machine-labeled data effectively, we adopted the transfer learning approach for the DNN-based NER model. The effect of our proposed method was verified with two different DNN-based NER models, with NER tasks conducted in two languages (English and Korean). Our experimental results demonstrate that the proposed method improves the performance of NER tasks, regardless of the DNN model and language used. For Korean, which has a small amount of labeled data, the average performance improvement was about 4 percentage points. The performance improvement was lower for English because there is an abundance of data. Nevertheless, our method improved the NER performance regardless of language. The remainder of this paper is organized as follows. We describe the related works in Section II, and the proposed method in Section III. The details of the experiments and results are discussed in Section IV. Finally, Section V concludes this paper. In summary, we proposed a method for improving NER with unlabeled data and small amounts of labeled data. The unlabeled data was automatically labeled by the bootstrapping and the bagging process to generate machine-labeled data. The machine-labeled data was then used for pre-training, and the pre-trained models were fine-tuned with golden standard data. In our experiments, direct training with the machine-labeled data decreased the performance because of mislabeling. By contrast, using machine-labeled data for pre-training increased the performance. The results of experiments constructed with restricted data or without word embeddings verified that our proposed method is effective for NER when the training data is insufficient. This is true, regardless of the model or language. Besides, our method can be applied to make performance improvements in any research field where there is a small amount of manually labeled data and freely available unlabeled data, such as in image processing and signal processing. We believe this study will serve as a reference for the use of unlabeled data in the effort to overcome the data insufficiency problem. However, the absolute performance of NER is still low. Therefore, we anticipate that the future direction of research in this area will be to enhance the quality of machine-labeled data.
