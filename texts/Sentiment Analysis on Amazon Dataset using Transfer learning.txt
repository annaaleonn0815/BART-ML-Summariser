Artificial Intelligence is a contiguous learning method by the computer approaching the real-life scenario as an input and giving a relevant human-like response. Machine Learning is a sub-domain of AI that is more concerned with understanding the underlying structure of the data and fitting that dataset into a particular learning model; gradually, the model is trained and gives the best response by itself. There are certain examples that illustrate this domain easily, such as Tesla, which invented the autonomous car that can drive on the road driverless. On the other hand, Google uses voice assistants and fingerprint verification on mobile phones, which are based on AI and ML techniques. In our project, we use a dataset of Amazon customer reviews and aim to train our model so that it can predict whether any new comment in real-time is positive or negative. In this research paper, we will show that we have used several Machine Learning and Deep Learning algorithms with various NLP vectorization techniques. Firstly, we discuss the Count Vectorizer vectorization, using three algorithms: Logistic Regression, Random Forest, and Multinomial Naïve Bayes. The accuracy for Logistic Regression is 76.5%, for Random Forest is 74.5%, and for Multinomial Naïve Bayes is 79%. Thus, Multinomial Naïve Bayes works best with Count Vectorizer. Secondly, we analyze TF-IDF vectorization with three algorithms: Logistic Regression, Random Forest, and Multinomial Naïve Bayes. The accuracy for Logistic Regression is 82.5%, for Random Forest is 81.0%, and for Multinomial Naïve Bayes is 83.5%. Therefore, Multinomial Naïve Bayes works best with TF-IDF. Thirdly, we explore Word2Vec vectorization with three algorithms: Logistic Regression, Random Forest, and Multinomial Naïve Bayes. The accuracy for Logistic Regression is 80%, for Random Forest is 75%, and for Bernoulli Naïve Bayes is 73.5%. Thus, Logistic Regression works best with Word2Vec. Fourthly, we investigate GloVe vectorization with three algorithms: RNN, LSTM, and Bi-LSTM. The accuracy for RNN is 58%, for LSTM is 77.6%, and for Bi-LSTM is 79.8%. Consequently, Bi-LSTM works best with GloVe. Lastly, we use transfer learning with the BERT model, specifically the Bi-encoder model. The accuracy of the transfer learning model is 82.76%. According to our research, the accuracy of the transfer learning model should be higher than any other model.
