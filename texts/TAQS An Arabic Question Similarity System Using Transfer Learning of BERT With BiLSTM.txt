Users still retrieve documents that contain content related to their query through traditional search engines. This could be time-consuming, especially as the amount of data posted on the web is huge and increasing rapidly. In 2021, there were over 1 billion sites on the world wide web. Taking advantage of this enormous quantity of available data is still a challenge. A traditional search engine based on information retrieval (IR) does not retrieve short answers to a query. The need for a question answering system that retrieves short answers has thus increased. In artificial intelligence and natural language processing (NLP), question answering (QA) remains a significant problem and one of the most researched fields. Manning and Schutze defined QA systems as "systems which try to answer a user query that is formulated in the form of a question by returning an appropriate noun phrase such as a location, a person, or a date." A QA system automatically answers human natural language questions. Community question answering (cQA) refers to questions asked and answered by users about various topics in an online forum. The digital footprint of human dialogues in those forums provides a great source for teaching question-answer models. Particularly, cQA forums such as Stackoverflow and Quora have an abundance of question-and-answer pairs. The rapid increase of question-answer pairs in such platforms results in the need for a way to automatically find relevant historic questions to newly asked questions, through question similarity, to answer new questions. cQA handles QA via different types of tasks, such as semantic question similarity matching, answer selection, and ranking question-answer pairs. Semantic textual similarity (STS) is an important component of many NLP tasks, including QA, document summarization, and IR. Moreover, the semantic question similarity task is an application of the STS task. STS is concerned with measuring the semantic equivalence of two text segments. The question similarity task is also concerned with detecting the semantic similarity between two questions. Two questions are defined as semantically similar if they can be correctly answered by the same answer. This task is a key step to automate the answering of new questions by reusing answers to semantically equivalent questions. The question similarity task is also known as question relevance, duplicate question detection, and recognizing question entailment. Some of the main challenges related to cQA NLP tasks is that the cQA forums consist of an open domain and non-factoid question-answer pairs, leading to extreme variance in the quality of question-answer pairs. Furthermore, cQA tasks require the neural network to comprehend the semantic component of texts because it must predict the semantic relation between two texts. Moreover, the questions in cQA forums contain long sentences ranging from a dozen words to hundreds of words. This paper contributed to the field of Arabic question similarity in two ways. First, it proposed the TAQS system with four question similarity models. They are four deep learning models for a real-world question similarity task, including two novel models. All the proposed models achieved significant performance gains. The models we presented to solve the task of semantic question similarity are BERT-BiLSTM, HT-BERT-BiLSTM, fine-tuned AraBERTv2, and fine-tuned AraBERTv0.2. The difference between the BERT-BiLSTM and HT-BERT-BiLSTM models is the feature extraction process: the former extracts the features from the fine-tuned AraBERT, and the latter extracts the features from the pre-trained AraBERT. We provided a thorough comparison of three approaches using the pre-trained language representation AraBERT. These were the fine-tuning approach through AraBERTv2 and AraBERTv0.2, the feature-based approach through BERT-BiLSTM, and a combined fine-tuning and feature-based approach through HT-BERT-BiLSTM. The proposed models were tested against BiLSTM and surpassed the performance of BiLSTM with SkipGram by a gain of 43.19%. In particular, HT-BERT-BiLSTM with the features of Layer 12 reached an accuracy of 94.45%, whereas AraBERTv2 and AraBERTv0.2 achieved 93.10% and 93.90% accuracy, respectively. This contributed to the proposed hybrid transfer learning, which positively affected the learning process. This finding demonstrates that combining fine-tuning and feature-based approaches through HT-BERT-BiLSTM enhances the performance of the semantic question similarity task. Second, we proposed, curated, and annotated an Arabic QA dataset, Tawasul. The Tawasul dataset contains 44,404 pairs of data, which are split into 36,016 training pairs and 8,388 testing pairs. Among the pre-processes that were applied to Tawasul for curation was splitting multiple similar questions in a single cell into separate cells. This increased the dataset by almost 1,000 entries and increased the number of candidate similar question examples from a maximum of 10 to a maximum of 14. Moreover, we applied the proposed rule-based approach to automatically annotate the Tawasul dataset by searching for suitable irrelevant examples and appending them. This method increased the dataset by 21,000, or 50% of the entries. The Tawasul dataset has features that have not yet been used, such as keywords and categories. As a future research direction, these features could be used to train machine learning models on different tasks, such as question generation or question classification. Furthermore, it would be interesting to evaluate and compare the effects of using other language models, such as generative pre-trained transformer (GPT), to extract the contextual feature word embedding to be fed to the neural network.
